{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence\n",
      "0     hackleme öğürme ve tükürme kısmı değil lütfen \n",
      "1  tamam  o zaman biraz fransız mutfağını denemey...\n",
      "2  mesele şu ki cameron  özellikle korkunç bir ez...\n",
      "3       kolayca bir randevu bulabilir gibi görünüyor\n",
      "4           tanrım kate bir erkek arkadaş bulabilsek\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"Data\\Turkish Dialog Data.txt\",sep=\";\", encoding=\"utf-8\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "swords = stopwords.words('turkish')\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    #sayıları silme\n",
    "    sentence = re.sub('[\\d\\s]',' ',str(sen))\n",
    "    #noktalama işaretlerini silme\n",
    "    sentence = re.sub('[^\\w\\s]',' ',str(sentence))\n",
    "    #birden çok boşluk silme\n",
    "    sentence = re.sub(r'\\s+',' ',sentence)\n",
    "    #tek karakterleri silme\n",
    "    sentence = re.sub(r\"\\b[\\w\\w]\\b\",' ',str(sentence))\n",
    "\n",
    "    #engellenecek kelimeleri silme\n",
    "    WPT = nltk.WordPunctTokenizer()\n",
    "    tokens = WPT.tokenize(sentence)\n",
    "    filtered_tokens = [token for token in tokens if token not in swords]\n",
    "    single_doc = ' '.join(filtered_tokens)\n",
    "\n",
    "    #hüçük harf dönüştürme\n",
    "    return single_doc.lower()\n",
    "\n",
    "x = data[\"Sentence\"]\n",
    "\n",
    "x = x.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 74944)\t1\n",
      "  (0, 210597)\t1\n",
      "  (0, 183596)\t1\n",
      "  (0, 177749)\t1\n",
      "  (0, 112439)\t1\n",
      "  (0, 41538)\t1\n",
      "  (0, 116655)\t1\n",
      "  (1, 167652)\t1\n",
      "  (1, 199530)\t1\n",
      "  (1, 23697)\t1\n",
      "  (1, 62187)\t1\n",
      "  (1, 124896)\t1\n",
      "  (1, 39457)\t1\n",
      "  (1, 126705)\t1\n",
      "  (1, 40516)\t1\n",
      "  (1, 35959)\t1\n",
      "  (1, 64128)\t1\n",
      "  (2, 121137)\t1\n",
      "  (2, 214277)\t1\n",
      "  (2, 101593)\t1\n",
      "  (2, 31347)\t1\n",
      "  (2, 209713)\t1\n",
      "  (2, 105755)\t1\n",
      "  (2, 23643)\t1\n",
      "  (2, 57730)\t1\n",
      "  :\t:\n",
      "  (342725, 213582)\t1\n",
      "  (342725, 87749)\t1\n",
      "  (342725, 38361)\t1\n",
      "  (342725, 18920)\t1\n",
      "  (342725, 51418)\t1\n",
      "  (342725, 87145)\t1\n",
      "  (342725, 58578)\t1\n",
      "  (342725, 73578)\t1\n",
      "  (342726, 87749)\t1\n",
      "  (342726, 78202)\t1\n",
      "  (342726, 195512)\t1\n",
      "  (342726, 73576)\t1\n",
      "  (342727, 87749)\t1\n",
      "  (342727, 78202)\t1\n",
      "  (342727, 195512)\t1\n",
      "  (342727, 73576)\t1\n",
      "  (342728, 27827)\t1\n",
      "  (342728, 205471)\t1\n",
      "  (342728, 198694)\t1\n",
      "  (342728, 130434)\t1\n",
      "  (342728, 124911)\t1\n",
      "  (342728, 91464)\t1\n",
      "  (342728, 153892)\t1\n",
      "  (342728, 95845)\t1\n",
      "  (342728, 73579)\t1\n"
     ]
    }
   ],
   "source": [
    "# Import the libraries we need\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Step 2. Design the Vocabulary\n",
    "# The default token pattern removes tokens of a single character. That's why we don't have the \"I\" and \"s\" tokens in the output\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# Step 3. Create the Bag-of-Words Model\n",
    "bag_of_words = count_vectorizer.fit_transform(data[\"Sentence\"])\n",
    "\n",
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           hackleme öğürme tükürme kısmı değil lütfen\n",
      "1    tamam zaman biraz fransız mutfağını denemeye d...\n",
      "2    mesele cameron özellikle korkunç bir ezik türü...\n",
      "3              kolayca bir randevu bulabilir görünüyor\n",
      "4             tanrım kate bir erkek arkadaş bulabilsek\n",
      "Name: Sentence, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "values = tfidf_vectorizer.fit(data[\"Sentence\"])\n",
    "val = values.transform(data[\"Sentence\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['secondvectorizer.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(values,\"secondvectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "x_train,x_test,y_train,y_test = train_test_split(bag_of_words,np.asarray(data[\"Sentence\"]))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
