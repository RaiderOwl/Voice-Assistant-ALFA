{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCEPb-doFkTB"
      },
      "source": [
        "#### Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5g90dlWDOAP",
        "outputId": "0c9bf612-fef7-4f9f-9d4c-f178bac43b96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                           sentence  label\n",
            "0                                   Cinema 4D kapat      3\n",
            "1                       PowerPoint  uygulamasını aç      3\n",
            "2  Şebnem Ferah Eşkıya Dünyaya Hükümdar Olmaz oynat      0\n",
            "3                           Ebru Gündeş Üç Kalp çal      0\n",
            "4                          Kahramanmaraş hava nasıl      1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"Data\\data.csv\",sep=\",\",encoding=\"utf-8\")\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clean Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osYs54pwFora",
        "outputId": "3aa6b158-0a78-425b-bc3f-13b1b72d49c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                        cinema kapat\n",
            "1                          powerpoint uygulamasını aç\n",
            "2    şebnem ferah eşkıya dünyaya hükümdar olmaz oynat\n",
            "3                             ebru gündeş üç kalp çal\n",
            "4                                  kahramanmaraş hava\n",
            "Name: sentence, dtype: object\n",
            "0    3\n",
            "1    3\n",
            "2    0\n",
            "3    0\n",
            "4    1\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\akinb\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_word_list = stopwords.words('turkish')\n",
        "\n",
        "import re\n",
        "\n",
        "def preprocess_text(sen):\n",
        "    #sayıları silme\n",
        "    sentence = re.sub('[\\d\\s]',' ',str(sen))\n",
        "    #noktalama işaretlerini silme\n",
        "    sentence = re.sub('[^\\w\\s]',' ',str(sentence))\n",
        "    #birden çok boşluk silme\n",
        "    sentence = re.sub(r'\\s+',' ',sentence)\n",
        "    #tek karakterleri silme\n",
        "    sentence = re.sub(r\"\\b[\\w\\w]\\b\",' ',str(sentence))\n",
        "\n",
        "    #engellenecek kelimeleri silme\n",
        "    WPT = nltk.WordPunctTokenizer()\n",
        "    tokens = WPT.tokenize(sentence)\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_word_list]\n",
        "    single_doc = ' '.join(filtered_tokens)\n",
        "\n",
        "    #hüçük harf dönüştürme\n",
        "    return single_doc.lower()\n",
        "\n",
        "x = data['sentence']\n",
        "y = data['label']\n",
        "\n",
        "x = x.apply(preprocess_text)\n",
        "\n",
        "print(x.head())\n",
        "print(y.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdu8J_fpGaus"
      },
      "source": [
        "#### Kelimelerin Vektörlere Dönüştürülmesi(TF/IDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "I-wer7uEGhhM"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vect = TfidfVectorizer(analyzer='word', lowercase=False)\n",
        "vect.fit(x)\n",
        "sent_vector = vect.transform(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['svmvectorizer.pkl']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(vect,\"svmvectorizer.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZwkuHLbHHvD"
      },
      "source": [
        "# Veri Setinin Test ve Train olarak ayrılması"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2chLJ0hHPIw",
        "outputId": "dfc494c5-00b6-4bf5-a87a-7a05ca9c3ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 530)\t0.4715683662502314\n",
            "  (0, 474)\t0.4295938445123894\n",
            "  (0, 230)\t0.7701119429726776\n",
            "  (1, 542)\t0.4162220011764153\n",
            "  (1, 425)\t0.3012769712441693\n",
            "  (1, 413)\t0.7570571435015578\n",
            "  (1, 302)\t0.2690330677239423\n",
            "  (1, 185)\t0.3007941526674786\n",
            "  (2, 651)\t0.4089952460071913\n",
            "  (2, 535)\t0.6092838017010285\n",
            "  (2, 32)\t0.6793350702917222\n",
            "  (3, 542)\t0.3605684814537448\n",
            "  (3, 532)\t0.41601339635972256\n",
            "  (3, 425)\t0.2609928829121422\n",
            "  (3, 302)\t0.2330603486021609\n",
            "  (3, 290)\t0.41601339635972256\n",
            "  (3, 273)\t0.5775140979554452\n",
            "  (3, 185)\t0.26057462255943864\n",
            "  (4, 511)\t0.3877063603244278\n",
            "  (4, 455)\t0.2146755538652099\n",
            "  (4, 452)\t0.3877063603244278\n",
            "  (4, 445)\t0.4792241314797847\n",
            "  (4, 333)\t0.4404207380625115\n",
            "  (4, 148)\t0.4792241314797847\n",
            "  (5, 596)\t0.6004636592286434\n",
            "  :\t:\n",
            "  (2084, 561)\t0.648891541589256\n",
            "  (2084, 536)\t0.648891541589256\n",
            "  (2084, 530)\t0.3973405774745865\n",
            "  (2085, 332)\t0.5113058235424321\n",
            "  (2085, 131)\t0.8593988333780744\n",
            "  (2086, 542)\t0.4321593801961708\n",
            "  (2086, 521)\t0.7347243647124332\n",
            "  (2086, 425)\t0.31281303917683767\n",
            "  (2086, 302)\t0.2793344981073561\n",
            "  (2086, 185)\t0.31231173320007505\n",
            "  (2087, 637)\t0.36706097481003297\n",
            "  (2087, 378)\t0.8021735969757839\n",
            "  (2087, 281)\t0.30453005036816766\n",
            "  (2087, 182)\t0.35922863124923954\n",
            "  (2088, 668)\t0.4273680940899667\n",
            "  (2088, 626)\t0.5394673857088726\n",
            "  (2088, 408)\t0.4273680940899667\n",
            "  (2088, 86)\t0.5394673857088726\n",
            "  (2088, 64)\t0.2294839946939388\n",
            "  (2089, 307)\t0.45755283368288857\n",
            "  (2089, 158)\t0.45755283368288857\n",
            "  (2089, 99)\t0.361364344046604\n",
            "  (2089, 97)\t0.45755283368288857\n",
            "  (2089, 64)\t0.1788782502340719\n",
            "  (2089, 44)\t0.45755283368288857\n",
            "2357    3\n",
            "2193    1\n",
            "543     3\n",
            "682     1\n",
            "1540    0\n",
            "       ..\n",
            "1731    3\n",
            "763     1\n",
            "835     2\n",
            "1653    0\n",
            "2607    0\n",
            "Name: label, Length: 2090, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(sent_vector,y,test_size=0.2,random_state=0)\n",
        "print(x_train)\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGQ4Qe45H2Ws"
      },
      "source": [
        "#### Geleneksel Makine Öğrenmesi Yöntemi : SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jkiqQH8H6xN",
        "outputId": "11bfed6b-cb3b-49d4-f703-a624b13f5dfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['svcmodel.pkl']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "import joblib\n",
        "\n",
        "# Başarı oranının değiştiği gözlemlenecektir. ( ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’ )\n",
        "svc = SVC(C=0.5,kernel='linear')\n",
        "\n",
        "svc.fit(x_train,y_train)\n",
        "joblib.dump(svc, \"svcmodel.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 592)\t0.4297793748965629\n",
            "  (0, 455)\t0.21285011017146235\n",
            "  (0, 411)\t0.3781710839889996\n",
            "  (0, 124)\t0.3844095893705985\n",
            "  (0, 103)\t0.3313303429736972\n",
            "  (0, 48)\t0.4297793748965629\n",
            "  (0, 12)\t0.4297793748965629\n",
            "  (1, 584)\t0.444446497274127\n",
            "  (1, 433)\t0.8151991384913686\n",
            "  (1, 64)\t0.37137269105803916\n",
            "  (2, 342)\t0.846723370378579\n",
            "  (2, 302)\t0.35468497432363516\n",
            "  (2, 185)\t0.3965578180338674\n",
            "  (3, 455)\t0.23845865449788142\n",
            "  (3, 213)\t0.48921330221554465\n",
            "  (3, 98)\t0.48921330221554465\n",
            "  (3, 49)\t0.47449816111461024\n",
            "  (3, 21)\t0.48921330221554465\n",
            "  (4, 677)\t0.3752604634518901\n",
            "  (4, 516)\t0.5409447492968189\n",
            "  (4, 301)\t0.5409447492968189\n",
            "  (4, 64)\t0.22612032139606097\n",
            "  (4, 50)\t0.4720240896797729\n",
            "  (5, 566)\t0.9382418273891142\n",
            "  (5, 302)\t0.3459801632139271\n",
            "  :\t:\n",
            "  (518, 84)\t0.29570190571586663\n",
            "  (518, 47)\t0.4237729142732062\n",
            "  (518, 36)\t0.40234947332533577\n",
            "  (519, 651)\t0.37857170348519037\n",
            "  (519, 600)\t0.6057849536203026\n",
            "  (519, 584)\t0.35033219271830657\n",
            "  (519, 414)\t0.6057849536203026\n",
            "  (520, 332)\t0.5113058235424321\n",
            "  (520, 106)\t0.8593988333780744\n",
            "  (521, 680)\t0.43454644629630335\n",
            "  (521, 577)\t0.43454644629630335\n",
            "  (521, 552)\t0.37589871845278505\n",
            "  (521, 505)\t0.34994668545368207\n",
            "  (521, 344)\t0.43454644629630335\n",
            "  (521, 235)\t0.36979833427183\n",
            "  (521, 64)\t0.18164476543263508\n",
            "  (522, 634)\t0.35983770551012884\n",
            "  (522, 455)\t0.18083613831503242\n",
            "  (522, 403)\t0.35983770551012884\n",
            "  (522, 292)\t0.35983770551012884\n",
            "  (522, 279)\t0.35983770551012884\n",
            "  (522, 248)\t0.35983770551012884\n",
            "  (522, 125)\t0.30222067098605815\n",
            "  (522, 57)\t0.346426692328226\n",
            "  (522, 6)\t0.3294444299371244\n"
          ]
        }
      ],
      "source": [
        "print(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N9cVfg5H9sk",
        "outputId": "e2f93970-6ad9-4b79-c76d-80397a9d169c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 3 1 0 0 1 1 3 0 1 3 3 0 2 3 0 0 0 3 1 1 0 1 0 0 1 2 0 2 3 0 3 2 1 0 3 0\n",
            " 0 3 0 3 0 0 0 0 3 3 2 0 1 3 2 3 3 3 0 3 1 2 3 2 1 1 1 3 0 0 3 0 3 1 0 0 3\n",
            " 3 0 3 0 0 1 0 3 0 0 3 1 0 3 0 3 1 0 1 0 3 0 1 3 3 0 0 1 1 1 1 0 1 3 3 1 0\n",
            " 1 0 3 1 2 1 1 3 0 3 1 2 3 1 0 3 1 0 1 3 3 2 0 0 2 0 3 2 0 1 1 3 3 3 3 3 0\n",
            " 0 3 3 0 2 0 0 3 1 0 1 0 3 0 1 2 0 3 1 0 3 1 3 0 3 3 2 0 2 0 3 3 1 0 1 1 0\n",
            " 1 0 3 0 1 2 1 3 3 3 3 3 0 3 1 2 3 3 1 0 0 0 0 0 1 1 0 0 3 0 2 1 2 3 3 2 0\n",
            " 2 0 1 0 3 2 3 0 1 3 3 3 0 1 1 2 0 2 3 0 3 3 2 3 2 0 1 0 2 0 0 0 3 1 0 2 0\n",
            " 3 1 0 3 1 0 2 2 3 3 0 3 2 1 3 2 0 3 0 2 1 2 2 1 2 0 0 3 0 0 2 3 0 0 1 1 0\n",
            " 2 3 0 0 1 3 1 0 2 0 2 1 1 0 0 3 3 1 2 3 1 3 0 0 3 0 3 2 1 2 0 0 0 0 3 0 3\n",
            " 0 2 2 3 2 0 0 1 2 3 0 3 2 3 2 0 1 0 1 0 2 0 3 0 2 1 2 0 3 1 3 0 3 2 1 1 0\n",
            " 0 1 2 3 0 0 0 1 2 2 2 0 3 1 2 3 1 3 1 1 3 3 3 2 3 0 3 2 1 3 1 2 2 2 2 1 1\n",
            " 3 1 2 3 3 3 3 0 1 3 2 3 3 2 0 0 3 0 1 0 3 0 0 0 1 2 0 0 1 1 2 0 3 0 0 3 2\n",
            " 0 2 1 2 2 3 0 1 2 1 1 0 1 3 1 3 0 1 0 3 2 0 0 2 3 3 3 1 0 0 1 3 0 0 0 3 3\n",
            " 2 0 0 0 2 1 0 2 1 1 3 0 1 1 1 3 0 3 0 1 0 0 2 0 3 1 1 1 2 0 2 0 0 1 1 0 3\n",
            " 2 3 3 0 0]\n"
          ]
        }
      ],
      "source": [
        "resultsvm = svc.predict(x_test)\n",
        "print(resultsvm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "525LNImSH_LQ",
        "outputId": "ef15cde9-896d-4ebd-a9e4-682294c905b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.0\n",
            "1.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1.0, 1.0, 1.0, None)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "clf = LogisticRegression(solver=\"liblinear\").fit(x_train, y_train)\n",
        "aucsvm = roc_auc_score(y_test, clf.predict_proba(x_test), multi_class='ovr')\n",
        "print(aucsvm)\n",
        "accsvm = accuracy_score(y_test,resultsvm)\n",
        "print(accsvm)\n",
        "\n",
        "precision_recall_fscore_support(y_test, resultsvm, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7Q_kFlDIvhQ"
      },
      "source": [
        "# Yapay Sinir Ağları : MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM6xNqzRIv70"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "modelmlp = Sequential()\n",
        "\n",
        "modelmlp.add(Dense(600,input_dim = 40065, activation = 'relu'))\n",
        "\n",
        "modelmlp.add(Dense(600,input_dim = 40065, activation = 'relu'))\n",
        "\n",
        "modelmlp.add(Dense(600,input_dim = 40065, activation = 'relu'))\n",
        "\n",
        "modelmlp.add(Dense(600,input_dim = 40065, activation = 'tanh'))\n",
        "\n",
        "modelmlp.add(Dense(5,input_dim = 40065, activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFgS9XWcw87w",
        "outputId": "9aaa08e1-f376-496a-847f-280b2526aded"
      },
      "outputs": [],
      "source": [
        "modelmlp.compile(loss='sparse_categorical_crossentropy',optimizer = 'adam',metrics =['accuracy'])\n",
        "modelmlp.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeXYDAG2xJgw",
        "outputId": "790a6d41-ecd4-4f47-c283-697e9350911b"
      },
      "outputs": [],
      "source": [
        "historymlp = modelmlp.fit(x_train, y_train, epochs=10, batch_size=32, verbose=2,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyO03XkS0QLu",
        "outputId": "c3161ea3-4989-416f-d0f4-346086b44ecb"
      },
      "outputs": [],
      "source": [
        "#model test\n",
        "scoremlptest = modelmlp.evaluate(x_test,y_test)\n",
        "\n",
        "print(\"test Loss:\",scoremlptest[0])\n",
        "print(\"test Accuracy:\",scoremlptest[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xOa3t_CNKDs",
        "outputId": "1f7fb5d8-5682-4f04-8c94-2518f190db21"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#confusion_matrix(y_test, resultmlp)\n",
        "print(resultmlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFsD05WtIwRF"
      },
      "source": [
        "#Derin Öğrenme Yöntemleri : RNN, LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjWyjPlkt8tj",
        "outputId": "bed0f422-7dcb-4ba5-ce44-2f78a821ae89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[  0   0   0 ...   0 147  12]\n",
            " [  0   0   0 ... 215   8   5]\n",
            " [  0   0   0 ... 371 230   6]\n",
            " ...\n",
            " [  0   0   0 ... 576  30   6]\n",
            " [  0   0   0 ...   4  16  33]\n",
            " [  0   0   0 ...   0 129   5]]\n"
          ]
        }
      ],
      "source": [
        "#Kelimeleri sayıya dönüştürme \n",
        "from keras.preprocessing.text import  Tokenizer\n",
        "from keras.preprocessing.sequence import  pad_sequences\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(x)\n",
        "xdl = token.texts_to_sequences(x)\n",
        "xdl = pad_sequences(xdl)\n",
        "print(xdl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXfN5ad0vGjC",
        "outputId": "78f3eef8-f1c8-4f9f-8405-01f1501cb9a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-0.02710634 -0.04167051 -0.09143805 ... -0.83658457  0.1064601\n",
            "  -0.38938777]\n",
            " [-0.02710634 -0.04167051 -0.09143805 ...  0.33250456 -0.68332427\n",
            "  -0.44107311]\n",
            " [-0.02710634 -0.04167051 -0.09143805 ...  1.18077388  0.57805796\n",
            "  -0.43368949]\n",
            " ...\n",
            " [-0.02710634 -0.04167051 -0.09143805 ...  2.29548677 -0.55832242\n",
            "  -0.43368949]\n",
            " [-0.02710634 -0.04167051 -0.09143805 ... -0.81483407 -0.63786905\n",
            "  -0.23433175]\n",
            " [-0.02710634 -0.04167051 -0.09143805 ... -0.83658457  0.00418586\n",
            "  -0.44107311]]\n"
          ]
        }
      ],
      "source": [
        "#Verileri ölçeklendirme standartlaştırma ve normalleştirme\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "xdl=scaler.fit_transform(xdl)\n",
        "print(xdl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBE-E-53vIxm",
        "outputId": "05fe9c74-eeba-4a3a-86d2-6781e8d32d10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [1. 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "#One Hot Encoding 0,1,2 Olan labellerımızı 1,0,0(Notr)/0,1,0(olumlu)/0,0,1(olumsuz) şekline getiriyoruz\n",
        "from keras.utils import  to_categorical\n",
        "\n",
        "ydl=to_categorical(y)\n",
        "print(ydl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Lm-IbV0zvKX0"
      },
      "outputs": [],
      "source": [
        "xdl_train,xdl_test,ydl_train,ydl_test = train_test_split(xdl,ydl,test_size=0.2,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YcC8Rowwe7h",
        "outputId": "4b571db9-9c36-4057-a5eb-d85f362b343a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2090, 12)\n",
            "(2090, 4)\n"
          ]
        }
      ],
      "source": [
        "print(xdl_train.shape)\n",
        "print(ydl_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqQWs6ry-jai"
      },
      "source": [
        "RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "f7SvhbrtIbKl"
      },
      "outputs": [],
      "source": [
        "#RNN Model17000\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, Embedding, Dropout\n",
        "\n",
        "modelrnn=Sequential()\n",
        "\n",
        "modelrnn.add(Embedding(480,256))\n",
        "\n",
        "modelrnn.add(SimpleRNN(256,activation='tanh',return_sequences=True,))\n",
        "\n",
        "modelrnn.add(SimpleRNN(256,activation='tanh'))\n",
        "\n",
        "modelrnn.add(Dense(5,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g7A_n78aOAf",
        "outputId": "4608f7cf-cf58-4d2d-c970-4dab3841b136"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 256)         122880    \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, None, 256)         131328    \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 386821 (1.48 MB)\n",
            "Trainable params: 386821 (1.48 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Model derlemesi\n",
        "\n",
        "modelrnn.compile(loss='categorical_crossentropy',optimizer ='adam',metrics=['accuracy'])\n",
        "modelrnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMsjjpOaaO_z",
        "outputId": "bf86b5ba-04db-4170-f2a6-653c2df05472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 4) and (None, 5) are incompatible\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#model eğitimi\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m historyrnn \u001b[38;5;241m=\u001b[39m \u001b[43mmodelrnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mydl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxdl_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mydl_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileo8448d2j.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 4) and (None, 5) are incompatible\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#model eğitimi\n",
        "historyrnn = modelrnn.fit(xdl_train, ydl_train, epochs=10, batch_size=32, verbose=2,validation_data=(xdl_test,ydl_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebyHzO2ZxjaZ",
        "outputId": "be9ebd19-decd-475e-f9b0-76d77fc3c9d3"
      },
      "outputs": [],
      "source": [
        "#model test\n",
        "scorernntest = modelrnn.evaluate(xdl_test,ydl_test)\n",
        "\n",
        "print(\"Test Loss:\",scorernntest[0])\n",
        "print(\"Test Accuracy:\",scorernntest[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUj4BE6iP3ku"
      },
      "outputs": [],
      "source": [
        "#from sklearn.metrics import accuracy_score\n",
        "#from sklearn.metrics import precision_recall_fscore_support\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#resultrnn = modelrnn.predict(xdl_test)\n",
        "#clf = LogisticRegression(solver=\"liblinear\").fit(xdl_train, ydl_train)\n",
        "#aucrnn = roc_auc_score(ydl_test, clf.predict_proba(xdl_test), multi_class='ovr')\n",
        "#print(aucrnn)\n",
        "\n",
        "#precision_recall_fscore_support(ydl_test, resultrnn, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GScN6uMkZhwQ"
      },
      "source": [
        "LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB3el_8DZjG_"
      },
      "outputs": [],
      "source": [
        "#LSTM \n",
        "from keras.layers import LSTM\n",
        "\n",
        "modellstm=Sequential()\n",
        "\n",
        "modellstm.add(Embedding(500,256))\n",
        "\n",
        "modellstm.add(LSTM(256,activation='tanh',return_sequences=True))\n",
        "\n",
        "modellstm.add(LSTM(256,activation='tanh'))\n",
        "\n",
        "modellstm.add(Dense(3,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCPfnsH4Zmib",
        "outputId": "7c0fd8b9-61ef-4a9b-d3cc-707ae4c63a65"
      },
      "outputs": [],
      "source": [
        "#Model derlemesi\n",
        "modellstm.compile(loss='categorical_crossentropy',optimizer ='adam',metrics=['accuracy'])\n",
        "modellstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9fvCbO2ZmmZ",
        "outputId": "8753d6c6-3aa0-43c8-d000-7dd80e652bf1"
      },
      "outputs": [],
      "source": [
        "#model eğitimi\n",
        "historylstm = modellstm.fit(xdl_train,ydl_train,epochs=10, batch_size=32,verbose=1,validation_data=(xdl_test,ydl_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqPja6hf0bZW",
        "outputId": "4af89d9a-cde5-4ba0-da5b-c1df434ce272"
      },
      "outputs": [],
      "source": [
        "#model test\n",
        "\n",
        "scorelstmtest = modellstm.evaluate(xdl_test,ydl_test)\n",
        "\n",
        "print(\"Test Loss:\",scorelstmtest[0])\n",
        "print(\"Test Accuracy:\",scorelstmtest[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm4VRA6SQUnG"
      },
      "outputs": [],
      "source": [
        "#from sklearn.metrics import accuracy_score\n",
        "#from sklearn.metrics import precision_recall_fscore_support\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#resultrnn = model.predict(x_test)\n",
        "#clf = LogisticRegression(solver=\"liblinear\").fit(xdl_train, ydl_train)\n",
        "#aucrnn = roc_auc_score(ydl_test, clf.predict_proba(xdl_test), multi_class='ovr')\n",
        "#print(aucrnn)\n",
        "\n",
        "#precision_recall_fscore_support(ydl_test, resultrnn, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1uEzNJ6-pYL"
      },
      "source": [
        "# Kelime Yerleştirme Yöntemleri : Word2Vec, Glove"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip3qyKCE-v9y"
      },
      "source": [
        "Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTVdI5qv_3Xh",
        "outputId": "5f07cf48-bfd2-4641-e43f-98c7fabad82c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['cinema', 'kapat']\n",
            "Word2Vec<vocab=691, vector_size=100, alpha=0.025>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "from gensim.models.word2vec import Word2Vec \n",
        "from keras.layers import  Dense,Dropout,Conv1D,MaxPool1D,GlobalMaxPool1D,Activation,LSTM\n",
        "from keras.models import Sequential\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "\n",
        "words = []\n",
        "for i in x:\n",
        "    words.append(i.split())\n",
        "\n",
        "print(words[0])\n",
        "\n",
        "word2vec_model = Word2Vec(words, window = 3, min_count=1, workers=16)\n",
        "print(word2vec_model)\n",
        "\n",
        "modelw2v = Sequential()\n",
        "\n",
        "modelw2v.add(LSTM(units=150))\n",
        "modelw2v.add(Dense(3,activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ4gApE5Qdtx",
        "outputId": "58de60d5-e9cf-47ff-f906-30651fb23f4f"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m modelw2v\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodelw2v\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3506\u001b[0m, in \u001b[0;36mModel.summary\u001b[1;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[0;32m   3475\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prints a string summary of the network.\u001b[39;00m\n\u001b[0;32m   3476\u001b[0m \n\u001b[0;32m   3477\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;124;03m    ValueError: if `summary()` is called before the model is built.\u001b[39;00m\n\u001b[0;32m   3504\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m-> 3506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis model has not yet been built. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBuild the model first by calling `build()` or by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3509\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on a batch of data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3510\u001b[0m     )\n\u001b[0;32m   3511\u001b[0m layer_utils\u001b[38;5;241m.\u001b[39mprint_summary(\n\u001b[0;32m   3512\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3513\u001b[0m     line_length\u001b[38;5;241m=\u001b[39mline_length,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3518\u001b[0m     layer_range\u001b[38;5;241m=\u001b[39mlayer_range,\n\u001b[0;32m   3519\u001b[0m )\n",
            "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ],
      "source": [
        "modelw2v.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "modelw2v.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlUhFKw8QnBN",
        "outputId": "2e856794-6e7b-4d93-8268-5b027bb9ea44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_3' (type Sequential).\n    \n    Input 0 of layer \"lstm_1\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 12)\n    \n    Call arguments received by layer 'sequential_3' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 12), dtype=float32)\n      • training=True\n      • mask=None\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m historyw2v \u001b[38;5;241m=\u001b[39m \u001b[43mmodelw2v\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mydl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxdl_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43mydl_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileo8448d2j.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\akinb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential_3' (type Sequential).\n    \n    Input 0 of layer \"lstm_1\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 12)\n    \n    Call arguments received by layer 'sequential_3' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 12), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "historyw2v = modelw2v.fit(xdl_train,ydl_train,batch_size=16,epochs=5,validation_data=(xdl_test,ydl_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPKLF-g1QnL6",
        "outputId": "00334093-a11a-4e9e-f0f7-5e7c23dc1a4f"
      },
      "outputs": [],
      "source": [
        "scorew2v = modelw2v.evaluate(xdl_test,ydl_test,verbose=0)\n",
        "\n",
        "print('Test Score : ',scorew2v[0])\n",
        "print('Test accuracy : ',scorew2v[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "If-rj7p6T1EO"
      },
      "outputs": [],
      "source": [
        "#from sklearn.metrics import accuracy_score\n",
        "#from sklearn.metrics import precision_recall_fscore_support\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#resultw2v= modelw2v.predict(xdl_test)\n",
        "#clf = LogisticRegression(solver=\"liblinear\").fit(xdl_train, ydl_train)\n",
        "#aucw2v = roc_auc_score(ydl_test, clf.predict_proba(xdl_test), multi_class='ovr')\n",
        "#print(aucw2v)\n",
        "\n",
        "#precision_recall_fscore_support(ydl_test, resultw2v, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdGOaVDJ_Hvt"
      },
      "source": [
        "# Değerlendirme Metrikleri : Accuracy, F-Measure, Precision, Recall, Sensitivity, AUC, Mattheww, Correlation Coefficent¶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ_nu9Zf_MSG"
      },
      "source": [
        "#Deep Learning Ezberlemediğinin Grafiği"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "TWedfdqDSdqg",
        "outputId": "186eb7da-ed72-410c-dfff-9e02d0a879e8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig,ax =plt.subplots(2,1)\n",
        "ax[0].plot(historymlp.history['loss'],color='b',label='Training loss')\n",
        "ax[0].plot(historymlp.history['val_loss'],color='r',label='Validation loss',axes=ax[0])\n",
        "legend=ax[0].legend(loc='best',shadow=True)\n",
        "\n",
        "ax[1].plot(historymlp.history['accuracy'],color='b',label='Training accuracy')\n",
        "ax[1].plot(historymlp.history['val_accuracy'],color='r',label='Validation accuracy')\n",
        "legend=ax[1].legend(loc='best',shadow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "yoyu-BR9q7dz",
        "outputId": "2b28709e-1498-4029-b6f7-de5f9481ef43"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig,ax =plt.subplots(2,1)\n",
        "ax[0].plot(historyrnn.history['loss'],color='b',label='Training loss')\n",
        "ax[0].plot(historyrnn.history['val_loss'],color='r',label='Validation loss',axes=ax[0])\n",
        "legend=ax[0].legend(loc='best',shadow=True)\n",
        "\n",
        "ax[1].plot(historyrnn.history['accuracy'],color='b',label='Training accuracy')\n",
        "ax[1].plot(historyrnn.history['val_accuracy'],color='r',label='Validation accuracy')\n",
        "legend=ax[1].legend(loc='best',shadow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EFBqyp1Vt3q"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig,ax =plt.subplots(2,1)\n",
        "ax[0].plot(historylstm.history['loss'],color='b',label='Training loss')\n",
        "ax[0].plot(historylstm.history['val_loss'],color='r',label='Validation loss',axes=ax[0])\n",
        "legend=ax[0].legend(loc='best',shadow=True)\n",
        "\n",
        "ax[1].plot(historylstm.history['accuracy'],color='b',label='Training accuracy')\n",
        "ax[1].plot(historylstm.history['val_accuracy'],color='r',label='Validation accuracy')\n",
        "legend=ax[1].legend(loc='best',shadow=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cvQk0BFD8_8r",
        "FCEPb-doFkTB",
        "NlOy6M9eF7mp",
        "Gdu8J_fpGaus",
        "SZwkuHLbHHvD",
        "PGQ4Qe45H2Ws",
        "V7Q_kFlDIvhQ",
        "KFsD05WtIwRF",
        "q1uEzNJ6-pYL",
        "XFA9YL6b-2tU",
        "oZ_nu9Zf_MSG"
      ],
      "name": "Text_Mining_Project.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
